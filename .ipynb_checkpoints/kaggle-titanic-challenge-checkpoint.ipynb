{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, KBinsDiscretizer, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for dirname, _, filenames in os.walk('kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        files.append(os.path.join(dirname, filename))\n",
    "        \n",
    "train_df = pd.read_csv(files[0])\n",
    "test_df = pd.read_csv(files[1])\n",
    "gender_df = pd.read_csv(files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:38.169114Z",
     "iopub.status.busy": "2024-07-15T12:57:38.168684Z",
     "iopub.status.idle": "2024-07-15T12:57:38.190478Z",
     "shell.execute_reply": "2024-07-15T12:57:38.189347Z",
     "shell.execute_reply.started": "2024-07-15T12:57:38.169079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:38.331861Z",
     "iopub.status.busy": "2024-07-15T12:57:38.331471Z",
     "iopub.status.idle": "2024-07-15T12:57:38.348656Z",
     "shell.execute_reply": "2024-07-15T12:57:38.347062Z",
     "shell.execute_reply.started": "2024-07-15T12:57:38.331830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis/Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:40.869329Z",
     "iopub.status.busy": "2024-07-15T12:57:40.868882Z",
     "iopub.status.idle": "2024-07-15T12:57:40.904910Z",
     "shell.execute_reply": "2024-07-15T12:57:40.903773Z",
     "shell.execute_reply.started": "2024-07-15T12:57:40.869292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:43.632264Z",
     "iopub.status.busy": "2024-07-15T12:57:43.631831Z",
     "iopub.status.idle": "2024-07-15T12:57:43.642571Z",
     "shell.execute_reply": "2024-07-15T12:57:43.641012Z",
     "shell.execute_reply.started": "2024-07-15T12:57:43.632231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values: We can see that Age, Cabin, and Embarked have null values\n",
    "# We will handle these null values as we preprocess each column at a time\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:43.731436Z",
     "iopub.status.busy": "2024-07-15T12:57:43.731019Z",
     "iopub.status.idle": "2024-07-15T12:57:43.740776Z",
     "shell.execute_reply": "2024-07-15T12:57:43.739590Z",
     "shell.execute_reply.started": "2024-07-15T12:57:43.731398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deleting PassengerId column, since it is merely an index, so not necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:44.033593Z",
     "iopub.status.busy": "2024-07-15T12:57:44.033174Z",
     "iopub.status.idle": "2024-07-15T12:57:44.041722Z",
     "shell.execute_reply": "2024-07-15T12:57:44.040312Z",
     "shell.execute_reply.started": "2024-07-15T12:57:44.033558Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop('PassengerId', axis=1, inplace=True)\n",
    "test_df.drop('PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing information from Embarked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 3 categorical variables for embarked. We can keep this info. One-hot encoding will be done later on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:46.130731Z",
     "iopub.status.busy": "2024-07-15T12:57:46.130327Z",
     "iopub.status.idle": "2024-07-15T12:57:46.138881Z",
     "shell.execute_reply": "2024-07-15T12:57:46.137539Z",
     "shell.execute_reply.started": "2024-07-15T12:57:46.130699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:46.234529Z",
     "iopub.status.busy": "2024-07-15T12:57:46.234100Z",
     "iopub.status.idle": "2024-07-15T12:57:46.246866Z",
     "shell.execute_reply": "2024-07-15T12:57:46.245141Z",
     "shell.execute_reply.started": "2024-07-15T12:57:46.234495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace null values with the most frequent element\n",
    "imp_majority = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "train_df[['Embarked']] = imp_majority.fit_transform(train_df[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a new categorical variable for AgeGroups, derived from Age**\n",
    "\n",
    "Source: https://integrishealth.org/resources/on-your-health/2015/october/stages-of-life-health-for-every-age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:48.838748Z",
     "iopub.status.busy": "2024-07-15T12:57:48.838342Z",
     "iopub.status.idle": "2024-07-15T12:57:48.858739Z",
     "shell.execute_reply": "2024-07-15T12:57:48.855871Z",
     "shell.execute_reply.started": "2024-07-15T12:57:48.838717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replacing all null ages to the average age\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train_df[['Age']] = imp_mean.fit_transform(train_df[['Age']])\n",
    "test_df[['Age']] = imp_mean.transform(test_df[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:48.952992Z",
     "iopub.status.busy": "2024-07-15T12:57:48.952230Z",
     "iopub.status.idle": "2024-07-15T12:57:48.962544Z",
     "shell.execute_reply": "2024-07-15T12:57:48.960852Z",
     "shell.execute_reply.started": "2024-07-15T12:57:48.952922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42, 80.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age'].min(), train_df['Age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:52.730956Z",
     "iopub.status.busy": "2024-07-15T12:57:52.730551Z",
     "iopub.status.idle": "2024-07-15T12:57:52.741921Z",
     "shell.execute_reply": "2024-07-15T12:57:52.740430Z",
     "shell.execute_reply.started": "2024-07-15T12:57:52.730911Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_age_group(age):\n",
    "    if age >= 0 and age <= 1:\n",
    "        return 0 # Infant\n",
    "    elif age >= 2 and age <= 4:\n",
    "        return 1 # Toddler\n",
    "    elif age >= 5 and age <= 12:\n",
    "        return 2 # Child\n",
    "    elif age >= 13 and age <= 19:\n",
    "        return 3 # Teenager\n",
    "    elif age >= 20 and age <= 39:\n",
    "        return 4 # Young adult\n",
    "    elif age >= 40 and age <= 59:\n",
    "        return 5 # Middle age adult\n",
    "    elif age >= 60:\n",
    "        return 6 # Senior\n",
    "\n",
    "# Extract 'Age' feature to get 10 different bins (Age groups)\n",
    "train_df['Age Group'] = train_df['Age'].apply(get_age_group)\n",
    "test_df['Age Group'] = test_df['Age'].apply(get_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:52.831738Z",
     "iopub.status.busy": "2024-07-15T12:57:52.831291Z",
     "iopub.status.idle": "2024-07-15T12:57:52.841044Z",
     "shell.execute_reply": "2024-07-15T12:57:52.839317Z",
     "shell.execute_reply.started": "2024-07-15T12:57:52.831703Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop('Age', axis=1, inplace=True)\n",
    "test_df.drop('Age', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:57:55.431875Z",
     "iopub.status.busy": "2024-07-15T12:57:55.431469Z",
     "iopub.status.idle": "2024-07-15T12:57:55.439728Z",
     "shell.execute_reply": "2024-07-15T12:57:55.438483Z",
     "shell.execute_reply.started": "2024-07-15T12:57:55.431840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, 3, 2, 6, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age Group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating new feature for Family Size (Parch + SibSp + Person themself)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:58:18.647362Z",
     "iopub.status.busy": "2024-07-15T12:58:18.646909Z",
     "iopub.status.idle": "2024-07-15T12:58:18.656311Z",
     "shell.execute_reply": "2024-07-15T12:58:18.654665Z",
     "shell.execute_reply.started": "2024-07-15T12:58:18.647328Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['Family Size'] = train_df['Parch'] + train_df['SibSp'] + 1\n",
    "test_df['Family Size'] = test_df['Parch'] + test_df['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:58:24.444661Z",
     "iopub.status.busy": "2024-07-15T12:58:24.444245Z",
     "iopub.status.idle": "2024-07-15T12:58:24.453031Z",
     "shell.execute_reply": "2024-07-15T12:58:24.451720Z",
     "shell.execute_reply.started": "2024-07-15T12:58:24.444629Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Parch', 'SibSp'], axis=1, inplace=True)\n",
    "test_df.drop(['Parch', 'SibSp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T12:58:24.535073Z",
     "iopub.status.busy": "2024-07-15T12:58:24.533922Z",
     "iopub.status.idle": "2024-07-15T12:58:24.542916Z",
     "shell.execute_reply": "2024-07-15T12:58:24.541513Z",
     "shell.execute_reply.started": "2024-07-15T12:58:24.535028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  5,  3,  7,  6,  4,  8, 11])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Family Size'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T22:28:44.533527Z",
     "iopub.status.busy": "2024-06-07T22:28:44.533049Z",
     "iopub.status.idle": "2024-06-07T22:28:44.553777Z",
     "shell.execute_reply": "2024-06-07T22:28:44.552689Z",
     "shell.execute_reply.started": "2024-06-07T22:28:44.533475Z"
    }
   },
   "source": [
    "**Create different categories for Fare, representing different fare groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare'].min(), train_df['Fare'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all null Fares to the average age\n",
    "imp_mean_2 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean_2.fit(train_df[['Fare']])\n",
    "test_df[['Fare']] = imp_mean_2.transform(test_df[['Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "\n",
    "train_df['Fare Bins'] = kbins.fit_transform(train_df[['Fare']])\n",
    "test_df['Fare Bins'] = kbins.transform(test_df[['Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Fare', inplace=True, axis=1)\n",
    "test_df.drop('Fare', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare Bins'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting titles from each passenger's name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Title'] = train_df['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "test_df['Title'] = test_df['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Name', inplace=True, axis=1)\n",
    "test_df.drop('Name', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Title'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Title'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some passengers based on title are from military or noble class.\n",
    "# In addition, there is also a mix of French/English female titles (Miss, Mrs, Ms, Mlle, Mme). We will convert French terms to English equivalence\n",
    "# Let's group these together\n",
    "\n",
    "replace_map = {\n",
    "    'Capt': 'Military',\n",
    "    'Col': 'Military',\n",
    "    'Don': 'Noble',\n",
    "    'Dona': 'Noble',\n",
    "    'Jonkheer': 'Noble',\n",
    "    'Lady': 'Noble',\n",
    "    'Major': 'Military',\n",
    "    'Mlle': 'Miss', # Mlle (Mademoiselle) - French title for unmarried woman\n",
    "    'Mme': 'Mrs', # Mme (Madame) - French title for married woman\n",
    "    'Sir': 'Noble',\n",
    "    'the Countess': 'Noble'\n",
    "}\n",
    "\n",
    "train_df['Title'] = train_df['Title'].replace(replace_map)\n",
    "test_df['Title'] = test_df['Title'].replace(replace_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Ticket number from Ticket strings, and getting ticket number length**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ticket number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket Number'] = train_df['Ticket'].apply(lambda x: x.split()[-1]) # Extracting numbers from ticket string\n",
    "train_df['Ticket Number Length'] = train_df['Ticket Number'].apply(lambda x: len(x)).astype(np.int32)\n",
    "train_df['Ticket Number Start'] = train_df['Ticket Number'].apply(lambda x: x[0]) # Starting value of ticket number\n",
    "\n",
    "test_df['Ticket Number'] = test_df['Ticket'].apply(lambda x: x.split()[-1])\n",
    "test_df['Ticket Number Length'] = test_df['Ticket Number'].apply(lambda x: len(x)).astype(np.int32)\n",
    "test_df['Ticket Number Start'] = test_df['Ticket Number'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Ticket', 'Ticket Number', 'Ticket Number Length', 'Ticket Number Start']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['Ticket Number Length'].unique())\n",
    "print(train_df['Ticket Number Start'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['Ticket Number Length'].unique())\n",
    "print(test_df['Ticket Number Start'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing prefixes of each ticket\n",
    " - There are too many unique categories for ticket prefixes (*High cardinality*)... For this notebook, I will not extract anything out of this. Prefixes may or may not be useful, but that is something that can be further researched in the future..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df['Ticket'].to_frame()\n",
    "temp['Ticket Content Amount'] = temp['Ticket'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing values of Ticket Content Amount = 2\n",
    "print(temp[temp['Ticket Content Amount'] == 2]['Ticket'].apply(lambda x: x.split()[0]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing values of Ticket Content Amount = 3\n",
    "print(temp[temp['Ticket Content Amount'] == 3]['Ticket'].apply(lambda x: x.split()[0]).unique())\n",
    "\n",
    "print(temp[temp['Ticket Content Amount'] == 3]['Ticket'].apply(lambda x: x.split()[1]).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop Ticket column, now that we've extracted out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Ticket', 'Ticket Number'], axis=1, inplace=True)\n",
    "test_df.drop(['Ticket', 'Ticket Number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting information from Cabin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with the most frequent element\n",
    "imp_majority_2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "train_df[['Cabin']] = imp_majority_2.fit_transform(train_df[['Cabin']])\n",
    "test_df[['Cabin']] = imp_majority_2.transform(test_df[['Cabin']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: Some members are assigned either 0, 1, 2, 3, or 4 cabins. This may be a useful feature to extract from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Cabin Amount'] = train_df['Cabin'].apply(lambda x: len(x.split())).astype(np.int32)\n",
    "test_df['Cabin Amount'] = test_df['Cabin'].apply(lambda x: len(x.split())).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Cabin Amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Cabin Amount'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T00:44:30.926635Z",
     "iopub.status.busy": "2024-06-12T00:44:30.926212Z",
     "iopub.status.idle": "2024-06-12T00:44:30.949519Z",
     "shell.execute_reply": "2024-06-12T00:44:30.948137Z",
     "shell.execute_reply.started": "2024-06-12T00:44:30.926572Z"
    }
   },
   "source": [
    "Notice how passengers owning multiple cabins all have cabins falling under the same deck (First character of each cabin). We can extract the letter from each cabin, which serves as the Deck. However, pay close attention to the ones owning 2 cabins... There are 4 strange columns where each string starts with the letter \"F\", followed by a space, and another cabin name.\n",
    " - For example, `F G73` in column 75.\n",
    "  \n",
    "The F Deck may be important, so we will keep this value for now ([Wikepedia on Titanic Decks](https://en.wikipedia.org/wiki/Titanic#:~:text=F%20Deck%2C%20the%20middle%20deck,pool%20and%20the%20Turkish%20bath.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    train_df[(train_df['Cabin'].str.startswith('F')) & (train_df['Cabin Amount'] == 2)],\n",
    "    test_df[(test_df['Cabin'].str.startswith('F')) & (test_df['Cabin Amount'] == 2)]],\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Deck'] = train_df['Cabin'].apply(lambda x : re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "test_df['Deck'] = test_df['Cabin'].apply(lambda x : re.compile(\"([a-zA-Z]+)\").search(x).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Cabin', axis=1, inplace=True)\n",
    "test_df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Deck'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View total amount of people passengers who did/did not survive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "sns.countplot(x='Survived', data=train_df)\n",
    "axes.set_title('Total Passengers who Did/Did Not Survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View distribution of each group of features: Survived, Pclass, Sex, Embarked, Age Group, Family Size, Fare Bins, Title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------add_suffix---------------------- Define the correct order for the age groups -----------------------------\n",
    "age_custom_labels = [\n",
    "    'Infant', 'Toddler', 'Child', 'Teen', 'Young Adult', 'Mid. Age Adult', 'Senior'\n",
    "]\n",
    "\n",
    "# ----------------------------- Create custom labels for Fare bins -----------------------------\n",
    "def create_custom_labels(bin_edges):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(len(bin_edges) - 1):\n",
    "        res.append(f'[{bin_edges[i]}, {bin_edges[i+1]})')\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "fare_bin_edges = np.round(kbins.bin_edges_[0], 2)\n",
    "fare_custom_labels = create_custom_labels(fare_bin_edges)\n",
    "\n",
    "# ----------------------------- Creating plots -----------------------------\n",
    "fig, axes = plt.subplots(6, 2, figsize=(20, 20))\n",
    "sns.countplot(x='Pclass', data=train_df, ax=axes[0, 0])\n",
    "sns.countplot(x='Sex', data=train_df, ax=axes[0, 1])\n",
    "sns.countplot(x='Embarked', data=train_df, ax=axes[1, 0])\n",
    "sns.countplot(x='Age Group', data=train_df, ax=axes[1, 1], order=[0, 1, 2, 3, 4, 5, 6])\n",
    "sns.countplot(x='Family Size',data=train_df, ax=axes[2, 0])\n",
    "sns.countplot(x='Fare Bins',data=train_df, ax=axes[2, 1], order=[0, 1, 2, 3, 4])\n",
    "sns.countplot(x='Title',data=train_df, ax=axes[3, 0])\n",
    "sns.countplot(x='Ticket Number Length',data=train_df, ax=axes[3, 1])\n",
    "sns.countplot(x='Ticket Number Start',data=train_df, ax=axes[4, 0], order=['L', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "sns.countplot(x='Cabin Amount',data=train_df, ax=axes[4, 1])\n",
    "sns.countplot(x='Deck',data=train_df, ax=axes[5, 0], order=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'])\n",
    "\n",
    "axes[1, 1].set_xticklabels(age_custom_labels);\n",
    "axes[2, 1].set_xticklabels(fare_custom_labels);\n",
    "\n",
    "fig.delaxes(axes[5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many people did or did not survive based on our categories? Let's visualize this below....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(20, 20))\n",
    "\n",
    "sns.barplot(x='Pclass', y='Survived', data=train_df, ax=axes[0, 0])\n",
    "sns.barplot(x='Sex', y='Survived', data=train_df, ax=axes[0, 1])\n",
    "sns.barplot(x='Embarked', y='Survived', data=train_df, ax=axes[1, 0])\n",
    "sns.barplot(x='Age Group', y='Survived', data=train_df, ax=axes[1, 1], order=[0, 1, 2, 3, 4, 5, 6])\n",
    "sns.barplot(x='Family Size', y='Survived', data=train_df, ax=axes[2, 0])\n",
    "sns.barplot(x='Fare Bins', y='Survived', data=train_df, ax=axes[2, 1], order=[0,1,2,3,4])\n",
    "sns.barplot(x='Title', y='Survived', data=train_df, ax=axes[3, 0])\n",
    "sns.barplot(x='Ticket Number Length',y='Survived', data=train_df, ax=axes[3, 1])\n",
    "sns.barplot(x='Ticket Number Start',y='Survived', data=train_df, ax=axes[4, 0], order=['L', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "sns.barplot(x='Cabin Amount',y='Survived', data=train_df, ax=axes[4, 1])\n",
    "sns.barplot(x='Deck',y='Survived', data=train_df, ax=axes[5, 0], order=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'])\n",
    "\n",
    "axes[1, 1].set_xticklabels(age_custom_labels);\n",
    "axes[2, 1].set_xticklabels(fare_custom_labels);\n",
    "\n",
    "fig.delaxes(axes[5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Preprocessing: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have preprocessed our data set to where all columns are categorical. Besides colummns that are already assigned numerical integers, preprocessing must be done on the remaining columns: \n",
    " - One Hot Encoding of Nominal Categories: Sex, Embarked, Title, Deck\n",
    " - Ordinal Encoding of Ordinal Categories: Ticket Number Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform='pandas')\n",
    "ohe.fit(train_df[['Sex', 'Embarked', 'Title', 'Deck']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = ohe.transform(train_df[['Sex', 'Embarked', 'Title', 'Deck']])\n",
    "test_encoded = ohe.transform(test_df[['Sex', 'Embarked', 'Title', 'Deck']])\n",
    "\n",
    "train_df = pd.concat([train_df, train_encoded], axis=1).drop(columns=['Sex', 'Embarked', 'Title', 'Deck'])\n",
    "test_df = pd.concat([test_df, test_encoded], axis=1).drop(columns=['Sex', 'Embarked', 'Title', 'Deck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinal Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [['L', '1', '2', '3', '4', '5', '6', '7', '8', '9']]\n",
    "ode = OrdinalEncoder(categories=categories).set_output(transform='pandas')\n",
    "ode.fit(train_df[['Ticket Number Start']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_2 = ode.transform(train_df[['Ticket Number Start']])\n",
    "test_encoded_2 = ode.transform(test_df[['Ticket Number Start']])\n",
    "\n",
    "train_df = pd.concat([train_df, train_encoded_2], axis=1).drop(columns='Ticket Number Start')\n",
    "test_df = pd.concat([test_df, test_encoded_2], axis=1).drop(columns='Ticket Number Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes make sense (Recall, that test_df does not contain Survival column like train_df)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Model Building: Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop('Survived', axis=1).to_numpy(), to_categorical(train_df['Survived']) # NOTE: to_categorical converts y_train to one hot encoded\n",
    "X_test = test_df.to_numpy()\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return Sequential([\n",
    "        Dense(units=128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=y_train.shape[1], activation='softmax') # NOTE: to_categorical converts y columns into one-hot encoded format\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the best learning rate using `LearningRateScheduler` callback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = create_model()\n",
    "\n",
    "EPOCHS = 200\n",
    "lr_schedule = LearningRateScheduler(lambda epoch: 1e-9 * 10**(epoch / 20)) # Expoentially increase learning rate by a factor of 10 after every 20 epochs\n",
    "optimizer = Adam(learning_rate=1e-7)\n",
    "                 \n",
    "nn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=32, validation_split=0.2, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning rate vs validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(history.history['learning_rate'], history.history['val_loss'])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Learning Rate vs. Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using optimal learning rate found to train our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = create_model()\n",
    "\n",
    "EPOCHS = 200\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
    "optimizer = Adam(learning_rate=1e-2)\n",
    "                 \n",
    "nn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=32, validation_split=0.2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_range, acc, label='Training Accuracy')\n",
    "ax.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(loss))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs_range, loss, label='Training Loss')\n",
    "ax.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test_pred = nn_model.predict(X_test)\n",
    "nn_test_pred_encoded = (nn_test_pred > 0.5).astype(int)\n",
    "\n",
    "nn_test_pred_decoded = []\n",
    "for t in nn_test_pred_encoded:\n",
    "    if t[0] == 1 and t[1] == 0: # Not Survived: [1, 0]\n",
    "        nn_test_pred_decoded.append(0)\n",
    "    elif t[0] == 0 and t[1] == 1: # Survived: [1, 0]\n",
    "        nn_test_pred_decoded.append(1)\n",
    "\n",
    "nn_survived = np.array(nn_test_pred_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model Building: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train2 = train_df.drop('Survived', axis=1).to_numpy(), train_df['Survived'].to_numpy() # Not one-hot encoded format\n",
    "X_test = test_df.to_numpy()\n",
    "\n",
    "X_train.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [5, 10, 15],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion=best_params['criterion'], \n",
    "                                  max_depth=best_params['max_depth'], \n",
    "                                  min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                  min_samples_split=best_params['min_samples_split'],\n",
    "                                  splitter=best_params['splitter'])\n",
    "dt_model.fit(X_train, y_train2)\n",
    "dt_survived = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model Building: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_leaf': [4, 5, 6],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(criterion=best_params['criterion'], \n",
    "                                  max_depth=best_params['max_depth'], \n",
    "                                  min_samples_leaf=best_params['min_samples_leaf'], \n",
    "                                  min_samples_split=best_params['min_samples_split'], \n",
    "                                  n_estimators=best_params['n_estimators'])\n",
    "\n",
    "rf_model.fit(X_train, y_train2)\n",
    "rf_survived = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:26:55.664274Z",
     "iopub.status.busy": "2024-07-07T09:26:55.663823Z",
     "iopub.status.idle": "2024-07-07T09:26:55.674549Z",
     "shell.execute_reply": "2024-07-07T09:26:55.673216Z",
     "shell.execute_reply.started": "2024-07-07T09:26:55.664236Z"
    }
   },
   "source": [
    "# 4) Model Building: Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model = AdaBoostClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=ab_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model = AdaBoostClassifier(learning_rate=best_params['learning_rate'],\n",
    "                             n_estimators=best_params['n_estimators'])\n",
    "\n",
    "ab_model.fit(X_train, y_train2)\n",
    "ab_survived = ab_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Model Building: Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "  'n_estimators' : [300, 400, 500],\n",
    "  'learning_rate': [ 0.1, 0.3, 0.6],\n",
    "  'max_depth': [8, 10, 12],\n",
    "  'min_samples_leaf': [50, 100, 120],\n",
    "  'max_features': [0.1, 0.3, 0.5] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(learning_rate=best_params['learning_rate'],\n",
    "                                     max_depth=best_params['max_depth'],\n",
    "                                     max_features=best_params['max_features'],\n",
    "                                     min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                     n_estimators=best_params['n_estimators'])\n",
    "\n",
    "gb_model.fit(X_train, y_train2)\n",
    "gb_survived = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Model Building: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "     'booster': ['gbtree', 'gblinear','dart'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(booster=best_params['booster'])\n",
    "\n",
    "xgb_model.fit(X_train, y_train2)\n",
    "xgb_survived = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Model Building: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1,2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(algorithm=best_params['algorithm'],\n",
    "                                n_neighbors=best_params['n_neighbors'],\n",
    "                                p=best_params['p'],\n",
    "                                weights=best_params['weights'])\n",
    "\n",
    "knn_model.fit(X_train, y_train2)\n",
    "knn_survived = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_votes(*classifications):\n",
    "    final_votes = []\n",
    "    test_len = classifications[0].shape[0] # 418\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(test_len):\n",
    "        votes_count = dict()\n",
    "        for c in classifications:\n",
    "            votes_count[c[i]] = votes_count.get(c[i], 0) + 1\n",
    "        final_votes.append(max(votes_count, key=votes_count.get))\n",
    "    \n",
    "    return np.array(final_votes)\n",
    "            \n",
    "survived = majority_votes(nn_survived, \n",
    "                           dt_survived, \n",
    "                           rf_survived, \n",
    "                           ab_survived, \n",
    "                           gb_survived, \n",
    "                           xgb_survived, \n",
    "                           knn_survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = pd.read_csv(files[1])['PassengerId'].to_numpy()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': survived\n",
    "})\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f\"/kaggle/working/submission_{datetime.now().strftime('%Y-%m-%d_%H%M%S')}.csv\", index=False)\n",
    "print(f\"Generated file /kaggle/working/submission_{datetime.now().strftime('%Y-%m-%d_%H%M%S')}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    " - https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79\n",
    " - https://annahava.medium.com/too-many-categories-how-to-deal-with-categorical-features-of-high-cardinality-d4563cfe62d6#:~:text=One%20of%20the%20most%20common,model%20and%20get%20modest%20results.\n",
    " - https://www.youtube.com/watch?v=6IGx7ZZdS74\n",
    " - https://www.ultravioletanalytics.com/blog/kaggle-titanic-competition-part-iv-derived-variables/\n",
    " - https://www.kaggle.com/code/ccastleberry/titanic-cabin-features"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
